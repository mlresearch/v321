@inproceedings{mccracken25a,
title = {Interpreting deep neural networks trained on elementary $p$ groups reveals algorithmic structure}
author = {McCracken, Gavin and Ayestas Hilgert, Arthur and Wei, Sihui and Moisescu-Pareja, Gabriela and Wang, Zhaoyue and Love, Jonathan},
pages = {1--14},
openreview = {NTXCFymNWu},
abstract = {We interpret deep neural networks (DNNs) trained on elementary $p$ group multiplication, examining how our results reveal some of the nature within major deep learning hypotheses. Assisted by tools from computational algebra and geometry, we perform analyses at multiple levels of abstraction, finding we can fully characterize and describe: 1) the global algorithm DNNs learn on this task---the multidimensional Chinese remainder theorem; 2) the neural representations, which are 2-torus $\mathbb{T}^2$ embedded in $\mathbb{R}^4$ encoding coset structure; 3) the individual neuron activation patterns, which activate solely on coset structures of the group. Furthermore, we find neurons learn the Lee metric to organize their activation strengths. Overall, our work serves as an exposition toward understanding how DNNs learn group multiplications.}
}